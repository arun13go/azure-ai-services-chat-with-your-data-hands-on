{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Processing\n",
    "Using Azure OpenAI service to extract key entities with OUT using Azure AI Document Intelligence service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Python PDF library\n",
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import helper libraries and load credentials from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create AOAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AOAI client using end point and key credentials\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"OPENAI_API_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),    \n",
    "  api_version='2023-05-15',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Setup PDF information\n",
    "Using sample PDF document from blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import openai\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "import shutil\n",
    "#from azure.storage.blob import ContainerClient, BlobServiceClient, BlockBlobService\n",
    "\n",
    "# Replace with your OpenAI API key and model\n",
    "my_ai_model = \"gpt-4o\"\n",
    "pdf_file_url = os.getenv(\"BLOB_SAS_URL\")\n",
    "print(pdf_file_url)\n",
    "\n",
    "with urlopen (pdf_file_url) as resp:\n",
    "    print(resp.read())\n",
    "\n",
    "local_file_name=\"sample-ukho-doc-process-using-aoai.pdf\"\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "with urllib.request.urlopen(pdf_file_url) as response, open(local_file_name, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read  PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text_list = []\n",
    "# Open the PDF file in binary mode\n",
    "with open(local_file_name, 'rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    #print(pdf_reader)\n",
    "    # Iterate through each page and extract text\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "        processed_text_list.append(page_text)\n",
    "\n",
    "# Combine all AI-processed text into a single string\n",
    "combined_text = \"\\n\".join(processed_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Now format the message to send to GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a Assistant, a backend processor.\n",
    "- User input is messy raw text extracted from a PDF page by PyPDF2.\n",
    "- Answer with polite and positive sense.\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Summarize the content:\" + combined_text\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Invoke GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=my_ai_model, # model = \"deployment_name\".\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Print the token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=452, prompt_tokens=5066, total_tokens=5518)\n"
     ]
    }
   ],
   "source": [
    "# print total token usage\n",
    "print(response.usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
